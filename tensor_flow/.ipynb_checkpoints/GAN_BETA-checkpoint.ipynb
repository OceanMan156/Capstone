{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81354a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Generator():\n",
    "    gen = tf.keras.Sequential()\n",
    "    gen.add(tf.keras.layers.Dense(16*16*384, use_bias = False, input_shape=(100,)))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    gen.add(tf.keras.layers.Reshape((16,16,384)))\n",
    "    gen.add(tf.keras.layers.Conv2DTranspose(192, (5,5), strides=(1,1), padding='same', use_bias = False))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    gen.add(tf.keras.layers.Conv2DTranspose(96, (5,5), strides=(2,2), padding='same', use_bias = False))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    gen.add(tf.keras.layers.Conv2DTranspose(48, (5,5), strides=(2,2), padding='same', use_bias = False))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    gen.add(tf.keras.layers.Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', use_bias = False, activation='tanh'))\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9427eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Discriminator():\n",
    "    dis = tf.keras.Sequential()\n",
    "    \n",
    "    dis.add(tf.keras.layers.Conv2D(96, (5,5), strides=(2,2), padding='same'))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    \n",
    "    dis.add(tf.keras.layers.Conv2D(192, (5,5), strides=(2,2), padding='same'))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    \n",
    "    dis.add(tf.keras.layers.Flatten())\n",
    "    dis.add(tf.keras.layers.Dense(1))\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(dis, flag):\n",
    "    dis.trainable = flag\n",
    "    for l in dis.layers:\n",
    "        l.trainable = flag\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(n, z):\n",
    "    return np.random.normal(0, 1, size=(n,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(n,z,Generator, index):\n",
    "    print(\"Samples:\")\n",
    "    samples = Generator.predict(make_noise(n,z))\n",
    "    samples = (samples + 1.0) / 2.0\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1,n, (i+1))\n",
    "        plt.imshow(samples[i].reshape(128,128,3))\n",
    "        plt.axis('off')\n",
    "    plt.savefig(\"GAN_\" + str(index) + \"_Epochs_Samples\",\n",
    "               bbox_inches='tight',\n",
    "               pad_inches = 0.5,\n",
    "               transparent = False,\n",
    "               dpi =400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadAndDecodeImage(imagePath): \n",
    "    rawImageData = tf.io.read_file(imagePath)\n",
    "    imageData = tf.io.decode_jpeg(rawImageData, channels = 3)\n",
    "    imageData = tf.image.convert_image_dtype(imageData, tf.float32)\n",
    "    imageData = tf.image.resize(imageData, (128, 128))\n",
    "    return imageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06571452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPath(imagePath):\n",
    "    return LoadAndDecodeImage(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated_output):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.ones_like(generated_output), logits = generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, generated_output):\n",
    "    real = tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.ones_like(real_output), logits = real_output)\n",
    "    generated = tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.zeros_like(generated_output), logits = generated_output)\n",
    "    total_loss = real + generated\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    path = os.getcwd() + \"/Samples/img_align_celeba/\" \n",
    "    dir_list = os.listdir(path)\n",
    "    for i in range(len(dir_list)):\n",
    "        dir_list[i] = path + dir_list[i]\n",
    "    \n",
    "    ds_file_path = np.array(dir_list)\n",
    "    trainFiles, testFiles = train_test_split(ds_file_path, train_size=0.8, random_state=42)\n",
    "    DS = tf.data.Dataset.from_tensor_slices(trainFiles)\n",
    "    VDS = tf.data.Dataset.from_tensor_slices(testFiles)\n",
    "    \n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    train_ds = DS.map(LoadAndDecodeImage, num_parallel_calls=AUTOTUNE)\n",
    "    test_ds = DS.map(LoadAndDecodeImage, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    train_np = tfds.as_numpy(train_ds)\n",
    "    test_np = tfds.as_numpy(test_ds)\n",
    "    \n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for images in train_np:\n",
    "        train_list.append(images)\n",
    "        \n",
    "    for images in test_np:\n",
    "        test_list.append(images)\n",
    "    \n",
    "    X_train = np.array(train_list)\n",
    "    X_test = np.array(test_list)\n",
    "    \n",
    "    epochs = 300\n",
    "    batch_size = 64\n",
    "    input_dim = 100\n",
    "    \n",
    "    Generator = Create_Generator()\n",
    "    Discriminator = Create_Discriminator()\n",
    "    \n",
    "    generator_optimizer = tf.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.optimizers.Adam(1e-4)\n",
    "    batch_no = int(len(X_train)/batch_size)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        for j in range(batch_no):\n",
    "            \n",
    "            rand_sample = np.random.randint(0, len(X_train), size=batch_size)\n",
    "           \n",
    "            image_batch = X_test[rand_sample]\n",
    "            \n",
    "            input_noise = make_noise(batch_size, input_dim)\n",
    "            \n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                \n",
    "                generated_images = Generator(input_noise, training=True)\n",
    "                real_output = Discriminator(image_batch, training=True)\n",
    "                generated_output = Discriminator(generated_images, training=True)\n",
    "\n",
    "                Generator_Loss = generator_loss(generated_output)\n",
    "                Discriminator_Loss = discriminator_loss(real_output, generated_output)\n",
    "    \n",
    "            \n",
    "            gradient_of_generator = gen_tape.gradient(Generator_Loss, Generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gradient_of_generator, Generator.trainable_variables))\n",
    "            \n",
    "            gradient_of_discriminator = disc_tape.gradient(Discriminator_Loss, Discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(gradient_of_discriminator, Discriminator.trainable_variables))\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch %i\" % i)\n",
    "            plot_sample(5, input_dim, Generator, i)\n",
    "    \n",
    "    baseline_model_accuracy = Discriminator.evaluate(generated_images, image_batch, verbose=0)\n",
    "\n",
    "    print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "    tf.keras.models.save_model(Generator, '.h5', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca629f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
