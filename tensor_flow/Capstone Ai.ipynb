{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81354a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Generator():\n",
    "    gen = tf.keras.Sequential()\n",
    "    gen.add(tf.keras.layers.Dense(256, input_dim = 100))\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.Dense(512))\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.Dense(1024))\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.Dense(2048))\n",
    "    gen.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    gen.add(tf.keras.layers.BatchNormalization())\n",
    "    gen.add(tf.keras.layers.Dense(784, activation='sigmoid'))\n",
    "    gen.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9427eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Discriminator():\n",
    "    dis = tf.keras.Sequential()\n",
    "    dis.add(tf.keras.layers.Dense(2048, input_dim = 784))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    dis.add(tf.keras.layers.Dense(1024))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    dis.add(tf.keras.layers.Dense(512))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    dis.add(tf.keras.layers.Dense(256))\n",
    "    dis.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    dis.add(tf.keras.layers.Dropout(0.3))\n",
    "    dis.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    dis.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(dis, flag):\n",
    "    dis.trainable = flag\n",
    "    for l in dis.layers:\n",
    "        l.trainable = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(n, z):\n",
    "    return np.random.normal(0, 1, size=(n,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(n,z,Generator, index):\n",
    "    print(\"Samples:\")\n",
    "    samples = Generator.predict(make_noise(n,z))\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1,n, (i+1))\n",
    "        plt.imshow(samples[i].reshape(28,28), cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(\"Samples/MNIST_\" + str(index) + \"_Epochs_Examples\",\n",
    "               bbox_inches='tight',\n",
    "               pad_inches = 0.5,\n",
    "               transparent = False,\n",
    "               dpi =400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X = X.reshape(len(X), 784)\n",
    "    X = X.astype('float32') / 255\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "   \n",
    "    X_train = normalize(X_train)\n",
    "    \n",
    "    Generator = Create_Generator()\n",
    "    Discriminator = Create_Discriminator()\n",
    "    \n",
    "    \n",
    "    np.random.seed(84)\n",
    "    make_trainable(Discriminator, False)\n",
    "    inputs = tf.keras.Input(shape=(100, ))\n",
    "    fakes = Generator(inputs)\n",
    "    output = Discriminator(fakes)\n",
    "    Gan = tf.keras.Model(inputs,output)\n",
    "    Gan.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "    \n",
    "    epochs = 1\n",
    "    batch_size = 128\n",
    "    input_dim = 100\n",
    "    batch_no = int(len(X_train)/batch_size)\n",
    "    Generator_Errors, Discriminator_Errors = (list(),list())\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        for j in range(batch_no):\n",
    "            \n",
    "            rand_sample = np.random.randint(0, len(X_train), size=batch_size)\n",
    "            image_batch = X_train[rand_sample]\n",
    "            \n",
    "            input_noise = make_noise(batch_size, input_dim)\n",
    "            generated_images = Generator.predict(input_noise)\n",
    "            X = np.concatenate((image_batch,generated_images))\n",
    "            \n",
    "            Y = np.concatenate([[0.9] * batch_size, [0.0] * batch_size])\n",
    "            \n",
    "            make_trainable(Discriminator, True)\n",
    "            Discriminator_Loss = Discriminator.train_on_batch(X,Y)\n",
    "            make_trainable(Discriminator, False)\n",
    "            \n",
    "            input_noise = make_noise(batch_size, input_dim)\n",
    "            fake_img = np.ones(batch_size)\n",
    "            for _ in range(4):\n",
    "                Generator_Loss = Gan.train_on_batch(input_noise, fake_img)\n",
    "\n",
    "        Generator_Errors.append(Generator_Loss)\n",
    "        Discriminator_Errors.append(Discriminator_Loss)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch %i\" % i)\n",
    "            plot_sample(20, input_dim, Generator, i)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(Discriminator_Errors, label='discriminitive loss')\n",
    "    plt.plot(Generator_Errors, label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f1975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
